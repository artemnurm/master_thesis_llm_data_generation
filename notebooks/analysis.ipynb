{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ результатов экспериментов по классификации страховых писем\n",
    "\n",
    "Данный notebook предназначен для интерактивного анализа результатов экспериментов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Добавляем путь к проекту\n",
    "project_root = Path('../')\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.data.data_loader import InsuranceDataLoader\n",
    "from src.data.data_analyzer import InsuranceLetterAnalyzer\n",
    "from src.utils.visualization import plot_class_distribution, generate_results_table\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка и анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "data_loader = InsuranceDataLoader()\n",
    "data_path = '../data/raw'\n",
    "\n",
    "train_df, test_df, services_df = data_loader.load_data(data_path)\n",
    "train_df = data_loader.preprocess_letters(train_df)\n",
    "test_df = data_loader.preprocess_letters(test_df)\n",
    "\n",
    "print(f\"Обучающая выборка: {len(train_df)} примеров\")\n",
    "print(f\"Тестовая выборка: {len(test_df)} примеров\")\n",
    "print(f\"Справочник услуг: {len(services_df)} услуг\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ распределения классов\n",
    "class_counts = train_df['class'].value_counts()\n",
    "print(\"Распределение классов:\")\n",
    "print(f\"Класс 0 (общие запросы): {class_counts[0]} ({class_counts[0]/len(train_df)*100:.1f}%)\")\n",
    "print(f\"Класс 1 (с кодами услуг): {class_counts[1]} ({class_counts[1]/len(train_df)*100:.1f}%)\")\n",
    "print(f\"Дисбаланс классов: {class_counts[0]/class_counts[1]:.1f}:1\")\n",
    "\n",
    "# Визуализация\n",
    "plot_class_distribution(train_df, title=\"Распределение классов в обучающей выборке\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Анализ текстовых характеристик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ длины текстов по классам\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Длина символов\n",
    "train_df.boxplot(column='text_length', by='class', ax=ax1)\n",
    "ax1.set_title('Длина текста (символы) по классам')\n",
    "ax1.set_xlabel('Класс')\n",
    "ax1.set_ylabel('Количество символов')\n",
    "\n",
    "# Количество слов\n",
    "train_df.boxplot(column='num_words', by='class', ax=ax2)\n",
    "ax2.set_title('Количество слов по классам')\n",
    "ax2.set_xlabel('Класс')\n",
    "ax2.set_ylabel('Количество слов')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Статистика по кодам услуг\n",
    "print(\"Статистика по кодам медицинских услуг:\")\n",
    "print(f\"Всего писем с кодами: {train_df['has_service_codes'].sum()}\")\n",
    "print(f\"Среднее количество кодов на письмо: {train_df[train_df['num_service_codes'] > 0]['num_service_codes'].mean():.2f}\")\n",
    "print(f\"Максимальное количество кодов: {train_df['num_service_codes'].max()}\")\n",
    "\n",
    "# Распределение количества кодов\n",
    "codes_dist = train_df['num_service_codes'].value_counts().sort_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "codes_dist.plot(kind='bar')\n",
    "plt.title('Распределение количества кодов услуг в письмах')\n",
    "plt.xlabel('Количество кодов')\n",
    "plt.ylabel('Количество писем')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Анализ результатов экспериментов\n",
    "\n",
    "**Примечание**: Для анализа результатов сначала запустите эксперименты с помощью `python main.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка результатов последнего эксперимента\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# Найти последний эксперимент\n",
    "results_dir = Path('../results')\n",
    "experiment_dirs = list(results_dir.glob('experiment_*'))\n",
    "\n",
    "if experiment_dirs:\n",
    "    latest_experiment = max(experiment_dirs, key=lambda p: p.stat().st_mtime)\n",
    "    results_file = latest_experiment / 'experiment_results.json'\n",
    "    \n",
    "    if results_file.exists():\n",
    "        with open(results_file, 'r', encoding='utf-8') as f:\n",
    "            results = json.load(f)\n",
    "        \n",
    "        print(f\"Загружены результаты из: {latest_experiment}\")\n",
    "        print(f\"Дата эксперимента: {results['experiment_info']['timestamp']}\")\n",
    "    else:\n",
    "        print(\"Файл результатов не найден. Запустите эксперименты: python main.py\")\n",
    "        results = None\n",
    "else:\n",
    "    print(\"Результаты экспериментов не найдены. Запустите: python main.py\")\n",
    "    results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ результатов, если они доступны\n",
    "if results and 'experiments' in results:\n",
    "    experiments = results['experiments']\n",
    "    \n",
    "    # Создание сводной таблицы\n",
    "    summary_data = []\n",
    "    \n",
    "    if 'baseline' in experiments:\n",
    "        baseline = experiments['baseline']\n",
    "        summary_data.append({\n",
    "            'Эксперимент': 'Базовая модель',\n",
    "            'F1-score': f\"{baseline['test_metrics']['f1_weighted']:.3f}\",\n",
    "            'Accuracy': f\"{baseline['test_metrics']['accuracy']:.3f}\",\n",
    "            'Precision': f\"{baseline['test_metrics']['precision_weighted']:.3f}\",\n",
    "            'Recall': f\"{baseline['test_metrics']['recall_weighted']:.3f}\"\n",
    "        })\n",
    "    \n",
    "    if 'synthetic_augmentation' in experiments:\n",
    "        for exp_name, exp_data in experiments['synthetic_augmentation'].items():\n",
    "            summary_data.append({\n",
    "                'Эксперимент': f'Синтетические ({exp_data[\"synthetic_size\"]})',\n",
    "                'F1-score': f\"{exp_data['test_metrics']['f1_weighted']:.3f}\",\n",
    "                'Accuracy': f\"{exp_data['test_metrics']['accuracy']:.3f}\",\n",
    "                'Precision': f\"{exp_data['test_metrics']['precision_weighted']:.3f}\",\n",
    "                'Recall': f\"{exp_data['test_metrics']['recall_weighted']:.3f}\"\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    display(summary_df)\n",
    "else:\n",
    "    print(\"Данные экспериментов недоступны для анализа.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация улучшений от синтетических данных\n",
    "if results and 'experiments' in results and 'synthetic_augmentation' in results['experiments']:\n",
    "    synthetic_results = results['experiments']['synthetic_augmentation']\n",
    "    baseline_f1 = results['experiments']['baseline']['test_metrics']['f1_weighted']\n",
    "    \n",
    "    sizes = []\n",
    "    f1_scores = []\n",
    "    improvements = []\n",
    "    \n",
    "    for exp_data in synthetic_results.values():\n",
    "        size = exp_data['synthetic_size']\n",
    "        f1 = exp_data['test_metrics']['f1_weighted']\n",
    "        improvement = ((f1 - baseline_f1) / baseline_f1) * 100\n",
    "        \n",
    "        sizes.append(size)\n",
    "        f1_scores.append(f1)\n",
    "        improvements.append(improvement)\n",
    "    \n",
    "    # Сортировка по размеру\n",
    "    sorted_data = sorted(zip(sizes, f1_scores, improvements))\n",
    "    sizes, f1_scores, improvements = zip(*sorted_data)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # График F1-score\n",
    "    ax1.plot(sizes, f1_scores, 'o-', linewidth=2, markersize=8, label='Синтетические данные')\n",
    "    ax1.axhline(y=baseline_f1, color='r', linestyle='--', label='Базовая модель')\n",
    "    ax1.set_title('Влияние размера синтетических данных на F1-score')\n",
    "    ax1.set_xlabel('Размер синтетических данных')\n",
    "    ax1.set_ylabel('F1-score')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # График улучшений\n",
    "    ax2.plot(sizes, improvements, 'o-', linewidth=2, markersize=8, color='green')\n",
    "    ax2.set_title('Относительное улучшение F1-score')\n",
    "    ax2.set_xlabel('Размер синтетических данных')\n",
    "    ax2.set_ylabel('Улучшение (%)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Выводы\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    print(f\"\\nЛучший результат достигнут с {sizes[best_idx]} синтетическими примерами:\")\n",
    "    print(f\"F1-score: {f1_scores[best_idx]:.3f} (улучшение на {improvements[best_idx]:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Выводы\n",
    "\n",
    "Основываясь на проведенном анализе, можно сделать следующие выводы:\n",
    "\n",
    "1. **Дисбаланс классов**: В исходных данных наблюдается значительный дисбаланс классов (~2.7:1)\n",
    "2. **Синтетические данные**: Генерация синтетических данных помогает улучшить качество классификации\n",
    "3. **Оптимальный размер**: Оптимальный размер синтетической выборки определяется экспериментально\n",
    "\n",
    "**Для получения полных результатов запустите эксперименты:**\n",
    "```bash\n",
    "python main.py --mode full\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}